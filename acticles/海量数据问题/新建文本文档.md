目录

> 1. 引言
> 2. 解决海量数据问题的四板斧
> 3. 例子
> 4. 小结



## 1. 引言

近年来，高并发、分布式以及大数据成了后端开发者绕不开的话题。当招聘软件上都写着有高并发、大数据等项目经历优先时，想必很多人都在暗暗心惊——项目都是 CRUD，也没机会接触到这些场景啊。

但是，有位伟人曾经说过：没有条件——创造条件。既然工作中接触不到高并发和大数据，我们可以弯道超车——平时在学习的时候，那如果在项目上或者面试中遇到这些大数据相关的问题时，我们应该怎么应对呢？



## 2. 海量数据问题的三板斧

#### 2.1 分治

众所周知，任何一个可用计算机求解的问题，其所需的计算时间都与其规模有关。问题规模越小，越容易求解，且所需的计算时间也越少。所以，对于大规模的数据问题，我们也可以分而治之，再合并结果即可。

![image-20230314204551621](img\image-20230314204551621.png)

* 分治算法是一个解决复杂问题的高效工具，它可以把问题分解成若干个子问题，把这些子问题逐个解决，再组合到一起形成大问题的答案。

* 计算机处理海量数据的问题，分治思想基本都是能够解决的，只不过一般情况下不会是最优方案，但可以作为一个 baseline。比如，在某些场景下我们可能需要逐渐优化子问题去达到一个最优解。**传统的归并排序就是分治思想，涉及到大量无法加载到内存的文件、排序等问题都可以用这个方法解决**。

- 分治算法的经典场景：数据量大无法加载到内存，为节省时间开销并行同步解决问题等。

  

#### 2.2 哈希（Hash）

Hash，散列函数，维基百科定义 hash 是一种从任何数据中创建小数字 “指纹” 的方法。通俗来讲就是：通过 hash 算法，数据元素可以被更快速地定位和查询。

![image-20230314210243091](img\image-20230314210243091.png)

Hash 获取某个 key 的时间复杂度是 O(1)，假设，有 n 个数通过 hash 函数存储到内存里，我们可以在常数时间内获取到某个 key 对应的 value。可以如此高效地访问数据，hash 很明显是我们解决大数据问题的一大利器。

而用 hash 来解决数据访问问题，也是相当粗暴的一种方式，存入取出即可，但粗暴却高效，**hash 唯一的缺点是耗内存，需要将数据全部载入内存。**

Hash 适用场景：快速查找，但需要足够大的内存可以存下所有数据。

> 要是数据量太大使得内存不足以存储所有数据，hash 可以结合分治来处理。



#### 2.3 位图&堆（bitMap&heap）

1. 位图(bitMap)

   - 位集这种思想其实简约而不简单，有很多扩展和技巧。比如多位表示一个数据(能够表示存在和数量问题)，BloomFilter (布隆过滤器就是一个典型的扩展)，在实际工作中应用场景很多，比如消息过滤等，读者需要掌握，但对于布隆过滤器使用有一些误区和不清楚的地方，读者可以看下面这篇博客避免这些性能上的误区。
   - 适用场景：可进行数据的快速查找，判重
   - 技能链接:布隆过滤器使用的性能误区

2. 堆(Heap)

   - 堆排序是一种比较通用的TopN问题解决方案，能够满足绝大部分的求最值的问题，读者需要掌握堆的基本操作和思想。
   - 适用场景:处理海量数据中TopN的问题(最大或最小)，要求N不大，使得堆可以放入内存
   - 技能链接:排序算法-Heap排序

   

### 1）海量个数字中，找出不重复的整数

**描述**

在 40 亿个整数中找出不重复的数字，注意：内存不足以容纳这么多个整数。

**分治法**

和前面题目类似，先拆分小文件，然后用 HashMap 统计，找出每个小文件中不重复整数，最后合并；

**位图法（bitMap）**

采用一个或多个 bit 来标记某个元素的值，键就是该元素，这样可以大大节省存储空间。位图通过数组来表示某些元素是否存在，它可以用于快速查找、判重和排序等。

1. 位图判重

我们用 2 个 bit 来表示数字出现的状态：00 表示没出现过、01 表示出现过一次、10 表示出现了多次。如果有 2^32 个整数（约为 40 亿），需要的内存为 2^32 * 2bit = 1GB。

当可用内存大于 1GB 时，可用位图法解决本题。通过遍历这 2^32 次方个数，将对应下标 00->01,01->10，最后统计 01（只出现了一次）的个数。

1. 位图排序

假设，我们对 [0，7] 中的几个元素（6,4,2,1,5）进行排序，可以用位图法：先申请 8bit 的空间（一个字节），然后遍历这 5 个元素，将元素下标置为1【0 1 1 0 1 1 1 0】。

遍历以后，我们再次遍历这个位数组，就可以得到最终的排序结果了：

```go
for i := 0; i < len(bitMap); i++ {
    if bitMap[i] == true {
       println(i)
   }
}
```

**布隆过滤器（BloomFilter）**

Bloom Filter 主要是用于判定目标数据是否存在于一个海量数据集 以及 集合求交集。以存在性判定为例：Bloom Filter 通过对目标数据的映射，能够以 O(k) 的时间复杂度判定目标数据的存在性，其中 k 为使用的 hash 函数个数。这样就能大大缩减遍历查找所需的时间。

但是 BloomFilter 有一定的误判率，大约在 0.0.1~0.05%，它可能会将不存在的数误判为已存在。



### 2）两个大文件里找到重复URL

**题目描述**

给定 a.txt，b.txt 两个文件，各存放 50 亿个 URL，每个 URL 各占 64B，内存限制是 8G。请找出 a、b 两个文件共同的 URL。

**分析**

文件大小为 50亿 * 64B = 320亿B = 3200万KB = 32000MB = 32GB，所以 8G 内存不足以一次性加载所有 URL 到内存中。

对于这种类型的题目，我们一般采用分治策略。即：把一个文件中的 URL 分为多个小文件，使得每个小文件大小不超过 4G，这样就可以把 a、b 对应的两个小文件放入内存处理，最终合并结果。

**思路**

首先遍历文件 a，对遍历到的 URL 通过哈希取模的方式：hash（URL）%10，根据计算结果把 URL 放入 a1，a2 ... a10.txt 这10个文件中，每个文件大小约为 3.2 GB。用同样的方法遍历文件 b，将 URL 拆分到 b1, b2 ... b10.txt 文件中。

拆分过后，所有可能相同的 URL 都在对应的小文件中，即 a1 对应 b1，...，a10 对应 b10。接下来只需求出这 10 对小文件中相同的 URL 就好了。求相同的 URL，可以用 HashSet/HashMap 的方式，当 URL 存在 Set/Map 中时，说明 URL 重复，就可以把重复的 URL 保存在单独的文件中。



### 3）大单词文件求频率Top100

**描述**

有一个1亿单词的文件，文件的每一行是一个单词，每个单词大小不超过 1B，内存大小限制为 1GB，要求返回频数最高的 100 个词（Top100）。

**分析**

由于内存限制，无法将大文件一次性读到内存中。因此，同样采用分治策略，将大文件拆分为小文件处理。

**思路**

首先遍历大文件，将每个单词哈希取模 hash(x)%1000，将结果存放到 a[i]（1<=i<=1000） 个文件中，每个文件存放大约 10万个单词，每个文件内存不超过 1GB。

接着使用 HashMap 来统计频数最高的 100 个单词，每个文件统计一次，最终得到 1000*100 = 10万个单词，再对这 10万个单词采用小顶堆的方式找出词中出现频数最高的 100个。

**小顶堆具体做法**

依次遍历每个小文件中词频最高的 100 个数，构建一个大小为 100 的小顶堆，如果遍历的词出现次数大于堆顶词的出现次数，则用新词替换旧词，然后重新调整小顶堆。遍历结束后，小顶堆上的 100 个词就是我们词频最高的 100 个单词。



### 4）海量日志数据提取频率最高的 IP

**描述**

现有一个装着访问 IP 的海量日志数据保存在一个超大文件中，无法读入内存，要求从中提取某天访问百度次数最多的那个 IP。

**思路**

此题只关心某天访问百度最多的 IP，因此可以先对文件进行遍历，把这天所有访问百度的 IP 提取到一个单独的文件中。再采用分治策略，拆分为小文件，用 HashMap 统计每个 IP 的次数，最后通过一个变量 maxCount 就可以找出重复次数最多的 IP。



### 5）海量电话号码中，统计不同号码的个数

解答思路：位图法，由于号码长度为 11 位，因此需申请长度为 1 千亿的 bit 数组（10^11），大约需要内存 10GB+。遍历所有的号码，当出现该号码时将该位置为 1，用一个数 count 记录第一次置为 1 的位图元素，遍历结束后得出最终结果。



参考资料：

海量问题六种解决思路：https://www.cnblogs.com/GarrettWale/p/14478347.html